[2024-01-23 10:22:52,413] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /root/space/conda_envs/hubc12/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121_nocublaslt.so
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 7.0
CUDA SETUP: Detected CUDA version 121
CUDA SETUP: Loading binary /root/space/conda_envs/hubc12/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121_nocublaslt.so...
num_gpus: 2, num_nodes: 1, buffer_factor: 1.0


estimate_zero2_model_states_mem_needs_all_live

Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 2 GPUs per node.
SW: Model with 33481M total params.
  per CPU  |  per GPU |   Options
  498.92GB |  62.36GB | offload_optimizer=cpu 
  249.46GB | 374.19GB | offload_optimizer=none
estimate_zero3_model_states_mem_needs_all_live

Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 2 GPUs per node.
SW: Model with 33481M total params, 262M largest layer params.
  per CPU  |  per GPU |   Options
  561.28GB |   0.98GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
  561.28GB |   0.98GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
  498.92GB |  32.16GB | offload_param=none, offload_optimizer=cpu , zero_init=1
  498.92GB |  32.16GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    1.95GB | 281.62GB | offload_param=none, offload_optimizer=none, zero_init=1
  249.46GB | 281.62GB | offload_param=none, offload_optimizer=none, zero_init=0
estimate_zero2_model_states_mem_needs_all_cold

